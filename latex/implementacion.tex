\subsection{Eliminación Gaussiana}

\subsubsection{Descripción del método}

El método de Eliminación Gaussiana consiste en una serie de pasos que permiten resolver un sistema de ecuaciones lineales de, en principio, $n$ ecuaciones y $n$ variables.

Sea A $\in \mathbb{R}^{n \times\ n}$ la matriz tal que el elemento en la fila $i$ y columna $j$ ($a_{i,j}$) representa el coeficiente de la variable $j$ en la ecuación $i$.
Y sea b $\in \mathbb{R}^{n}$ el vector tal que el elemento en la fila $i$ ($b_{i}$) representa el termino independiente en la ecuación $i$.

Podemos dividir el método en 2 partes centrales:
\begin{enumerate}
    \item Llevar la matriz A a una forma \textbf{Triangular Superior}, es decir, una matriz equivalente a A tal que tiene ceros debajo de los elementos de la diagonal. El siguiente pseudocódigo muestra como es el algoritmo para realizar esta tarea:

\begin{lstlisting}
Para j desde 0 hasta n-1 hacer:
    Poner pivote = A[j][j]
    Para i desde j+1 hasta n-1 hacer:
        Poner coeficiente = A[i][j] / pivote
        Poner A[i][j] = 0
        Para k desde j+1 hasta n-1 hacer:
            Poner A[i][k] = A[i][k] - coeficiente * A[j][k]
        Fin para
        b[i] = b[i] - coeficiente * b[j]
    Fin para
Fin para
\end{lstlisting}

		Notese que no validamos que la variable ``pivote'' sea distinta de cero. Esto es así ya que por la forma en la que se modeló el problema el pivote siempre es distinto de cero.

    \item \textbf{Resolver el sistema equivalente}. Para esto, vamos a utilizar que la matriz es Triangular Superior. La idea es empezar despejando el valor de la $n$-ésima variable, luego usar este valor para despejar la $(n-1)$-ésima variable, y así sucesivamente hasta la primera variable. En pseudocódigo:

\begin{lstlisting}
Poner X = vector de n elementos
Para i desde n-1 hasta 0 hacer:
    Poner X[i] = b[i]
    Para j desde i+1 hasta n-1 hacer:
        Poner X[i] = X[i] - U[i][j] * X[j]
    Fin para
    Poner X[i] = X[i] / U[i][i]
Fin para
\end{lstlisting}

		Donde $U$ es la matriz que calculamos en el paso 1.

  \end{enumerate}


\subsubsection{Utilizando que la matriz es Banda}

Si miramos la matriz con la cual representamos el modelo del problema, podemos ver que alrededor de los elementos de la diagonal hay una ``banda'' de tamaño $2n$.
Es decir, si quisieramos poner elementos debajo del elemento $a_{i,i}$, nos bastaría con modificar las filas desde $i+1$ hasta $i+2n+1$, ya que $\forall\ a_{j,i},\ j> i+2n+1 \implies a_{j,i} = 0$.

Usando esto podemos optimizar significativamente el primer paso de la Elminación Gaussiana, que consiste en hallar la matriz equivalente Triangular Superior. El pseudocódigo es el siguiente:

\begin{lstlisting}
Para j desde 0 hasta n-1 hacer:
    Poner pivote = A[j][j]
    Poner inicioBanda = max(i+1, n)
    Poner finBanda = min(n, inicioBanda + n)
    Para i desde inicioBanda hasta finBanda hacer:
        Si A[i][j] != 0 hacer:
            Poner coeficiente = A[i][j] / pivote
            Poner A[i][j] = 0
            Para k desde j+1 hasta n-1 hacer:
                Poner A[i][k] = A[i][k] - coeficiente * A[j][k]
            Fin para
            b[i] = b[i] - coeficiente * b[j]
        Fin si
    Fin para
Fin para
\end{lstlisting}

\subsection{Factorización LU}

Dada la matriz A $\in \mathbb{R}^{n \times\ n}$, los vectores x $\in \mathbb{R}^{n}$ y b $\in \mathbb{R}^{n}$ y la ecuación $Ax = b$, esta técnica de resolución descompone la matriz en cuestión de la siguiente manera:

\begin{center}
    $A = LU$ con L,U $\in \mathbb{R}^{n \times\ n}$\\
    L es triangular inferior con 1's en los elementos de su diagonal\\
    U es triangular superior\\
    Y por lo tanto, $Ux = y$, $Ly = b$ reemplazando la ecuación original
\end{center}

Ahora, como vimos en las clases prácticas y teóricas, estas dos matrices son únicas y la forma de obtenerla es haciendo los pasos de eliminación gaussiana (descripta anteriormente) y guardarnos los coeficientes por los cuáles vamos multiplicando las filas para triangular las de abajo. A modo de ejemplo:

\newenvironment{spmatrix}[1]
 {\def\mysubscript{#1}\mathop\bgroup\begin{pmatrix}}
 {\end{pmatrix}\egroup_{\textstyle\mathstrut\mysubscript}}

\newcommand*{\temp}[1]{\multicolumn{1}{c|}{#1}}

\begin{equation*}
\begin{spmatrix}{A}
    5 & −1 & 2 \\
    10 & 3 & 7 \\
    15 & 17 & 19
\end{spmatrix}
=
\begin{spmatrix}{L}
    1 & 0 & 0 \\
    2 & 1 & 0 \\
    3 & 4 & 1
\end{spmatrix}
\times
\begin{spmatrix}{U}
    5 & −1 & 2 \\
    0 & 5 & 3 \\
    0 & 0 & 1
\end{spmatrix}
\end{equation*}

En términos de espacio, guardar las matrices L y U se puede hacer en una 'misma' matriz si se la interpreta de forma diferente. Lo que hay que tener en cuenta que la única parte relevante de U es de la diagonal para arriba (con la diagonal inclusive), pero de L ya sabemos que la diagonal contiene 1's y solo nos interesa saber la parte de abajo. Entonces la matriz anterior se podría guardar así en memoria:

\begin{equation*}
\begin{spmatrix}{L}
    1 & 0 & 0 \\
    2 & 1 & 0 \\
    3 & 4 & 1
\end{spmatrix}
\begin{spmatrix}{U}
    5 & −1 & 2 \\
    0 & 5 & 3 \\
    0 & 0 & 1
\end{spmatrix}
\leftarrow
\left(
\begin{array}{cccc}
5 & -1 & 2 \\ \cline{1-1}
\temp{2} & 5 & 3 \\ \cline{2-2}
3 & \temp{4} & 1
\end{array}
\right)
\end{equation*}

Además, como ya demostramos que la matriz se puede triangular mediante eliminación gaussiana sin pivoteo, sabemos que la factorización LU existe (y no tenemos que tomar matrices de permutación). \\
Teniendo todo eso en cuenta, encontramos la factorización (con el formato explicado antes) con este procedimiento:

\begin{lstlisting}
Sea A la matriz que queremos factorizar
Sea n la cantidad de filas (y columnas, porque es cuadrada) de A
Sea M una matriz de n*n (donde guardaremos la respuesta)

FactorizarLU(A, n, M)
    Copiar la primer fila de A hacia M
    Para i desde 0 hasta n-2
        Para j desde i+1 hasta n-1
            Poner c = A[j][i]/A[i][i]
            Poner M[j][i] = c
            Para k desde i+1 hasta n-1
                M[j][k]-= c*A[i][k]
    devolver M
\end{lstlisting}

Ya teniendo la factorización LU de A, solo quedaría resolver las ecuaciones $Ux = y$, $Ly = b$ adaptando los algoritmos clásicos de triangulación de sistemas lineales para que tomen en cuenta el formato con el cual guardamos la factorización LU de A en una sola matriz:

\begin{lstlisting}
Sean A, n y M definidos como el pseudocódigo anterior

ResolverSistema(A,n,b)
    M = Crear matriz cuadrada de n*n
    FactorizarLU(A,n,M)
    x = Crear vector de n elementos
    ResolverTriangularSuperiorLU(M,x)
    y = Crear vector de n elementos
    ResolverTriangularInferiorLU(M,y)
    devolver y

ResolverTriangularSuperiorLU(M,x)
    Para i desde n-1 hasta 0
        Poner x[i] = b[i]
        Para j desde i+1 hasta n-1
            Poner x[i] = x[i] - U[i][j] * x[j]
        Poner x[i] = x[i] / U[i][i]

ResolverTriangularInferiorLU(M,y)
    Para i desde 0 hasta n-1
        Poner x[i] = b[i]
        Para j desde i+1 hasta n-1
            Poner x[i] = x[i] - U[i][j] * x[j]
        Poner x[i] = x[i] / U[i][i]

for(int i = 0; i < n; ++i) {
    x[i] = b[i];
    for (int j = 0; j < i; ++j) {
        x[i] -= x[j] * L[i][j];
    }
    // la diagonal es 1, asi que no hay que dividir por nada
}

Copiar la primer fila de A hacia M
Para i desde 0 hasta n-2
    Para j desde i+1 hasta n-1
        Poner c = A[j][i]/A[i][i]
        Poner M[j][i] = c
        Para k desde i+1 hasta n-1
            M[j][k]-= c*A[i][k];
\end{lstlisting}

\subsection{Determinación de la Isoterma}

Recordemos que nuestra discretización particiona una sección circular del Alto Horno de la siguiente forma:
 \begin{itemize}
 	\item $0 = \theta_0 < \theta_1 < ... < \theta_n = 2\pi$ en $n$ \'angulos discretos, y
 	\item $r_i = r_0 < r_1 < ... < r_m = r_e$ en $m+1$ radios discretos
 \end{itemize}

Luego, para cada ángulo $j$ tenemos los puntos: $t_{i,j}$ con $0 \leq i \leq m$.

Entonces, hallar la isoterma $C$ equivale a, para cada ángulo $j$, hallar el radio $r_C$ tal que $T(r_C, \theta_j) = C$.

\subsubsection{Promedio simple}

Este método consiste en, dado un ángulo $j$, buscar un punto $t_{i,j}$ en la solución del sistema tal que $t_{i,j} \leq C \leq t_{i+1,j}$.

Una vez hallado este punto, tenemos que $r_C = \frac{r_i + r_{i+1}}{2}$.

\subsubsection{Búsqueda binaria mediante sistemas de ecuaciones}



\subsubsection{Regresión lineal (Linear fit)}

Este método utiliza el algoritmo de regresión lineal para, dado un ángulo $j$, y usando todos los puntos $t_{i,j}$ con $0 \leq i \leq m$, hallar una función lineal que aproxime dichos puntos lo mejor posible.
Como la función que estamos buscando es lineal, es de la forma: $y(x) = a + bx$, donde $b$ es el coeficiente principal, $a$ el termino independiente, $x$ es un radio sobre el ángulo $j$ e $y(x)$ es la temperatura para dicho radio.

Luego, el algoritmo de regresion lineal basicamente utiliza la minimización de la suma de las distancias al cuadradado desde los puntos a la función lineal. Esto se logra calculando la derivada con respecto a $a$ y $b$ y fijando estos en cero.

Entonces, si definimos:

$$\overline{x} = \frac{1}{m}\sum_{i=0}^{m}{r_i} \quad\quad\quad \overline{y} = \frac{1}{m}\sum_{i=0}^{m}{t_{i,j}}$$

$$S_x = \sum_{i=0}^{m}{(r_i - \overline{x})^2} \quad\quad\quad S_{xy} = \sum_{i=0}^{m}{(r_i - \overline{x})(t_{i,j} - \overline{y})}$$

Tenemos que:

$$b = \frac{S_{xy}}{S_x}  \quad\quad\quad a = \overline{y} - b\overline{x}$$

Una vez obtenidos $a$ y $b$, para hallar la isoterma $C$ en el ángulo $j$, basta con calcular:

$$r_C = |C - a|/b$$

En pseudocódigo:

\begin{lstlisting}[mathescape=true]
Poner solucion = vector de n elementos
Para j desde 0 hasta n hacer:
    Poner avgX = 0
    Poner avgY = 0
    Para i desde 0 hasta m hacer:
        Poner avgX = avgX + $r_i$
        Poner avgY = avgY + $t_{i,j}$
    Fin para
    Poner avgX = avgX / m
    Poner avgY = avgY / m
    Poner numerador = 0
    Poner denominador = 0
    Para i desde 0 hasta m hacer:
        Poner numerador = numerador + ($r_i$ - avgX) * ($t_{i,j}$ - avgY)
        Poner denominador = denominador + ($r_i$ - avgX) * ($r_i$ - avgX)
    Fin para
    Si denominador == 0 hacer:
        Poner denominador = 1
    Fin si
    Poner coeficiente = numerador / denominador
    Poner independiente = avgY - slope * coeficiente
    Poner solucion[j] = abs(C - independiente) / coeficiente
Fin para
\end{lstlisting}

\subsection{Evaluación del peligro de la estructura}

Una vez obtenida la isoterma $C$, queremos evaluar la peligrosidad de la estructura en función de la distancia de la isoterma a la pared externa del horno. En este sentido, estamos asumiendo que la temperatura $C$ es elevada y que mientras más cercana está la temperatura de la pared externa a $C$, entonces más peligrosa es la estructura.

En base a esto, proponemos dos medidas distintas para evaluar la peligrosidad.

\subsubsection{Proximidad porcentual simple}

Para cada ángulo $j$, podemos calcular el coeficiente porcentual $\Delta_j(C) = (r_e - r_C)/(r_e - r_i)$, donde $r_e$ es el radio de la pared externa del horno, $r_i$ el radio de la pared interna, y $r_C$ el radio de la isoterma $C$ para el ángulo $j$.

Notese que $r_i \leq r_C \leq r_e$, y por lo tanto si $r_C = r_i \implies \Delta_j(C) = 1$, y si $r_C = r_e \implies \Delta_j(C) = 0$.

De esta forma, podemos definir un $\varepsilon_C$, con $0 < \varepsilon_C < 1 $, tal que decimos que la estructura se encuentra en peligro si:

$$\varepsilon_C \geq \min\limits_{\substack{1 \leq j \leq n-1}}(\Delta_j(C))$$

\subsubsection{Proximidad porcentual promediada}

En la medida anterior, podría pasar que para un $j'$ dado $\Delta_{j'}(C) < \varepsilon_C$ pero el resto de los $\Delta_j(C)$ sean mayores a $\varepsilon_C$, en cuyo caso, igualmente la estructura sería catalogada como peligrosa.

Entonces, querriamos dar una medida de la peligrosidad de la estructura que tome en cuenta todos los angulos. Para esto, vamos a tomar el promedio de todos los $\Delta_j(C)$, definidos como en la medida anterior para cada ángulo $j$, y decimos que la estructura se encuentra en peligro si:

$$\Delta(C)= \frac{\sum\limits_{j=1}^{n}{\Delta_j(C)}}{n} \leq  \varepsilon_C$$
